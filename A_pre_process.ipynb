{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"Radiate_Image_Dataset/tiny_foggy/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lidar_to_camera_frame.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "def create_frames(lines):\n",
    "    frames=[]\n",
    "    for line in lines:\n",
    "        temp = line.split()\n",
    "        if len(temp[3])<20:\n",
    "            dif = 20-len(temp[3])\n",
    "            zeros = '0'*dif\n",
    "            num = temp[3].split(\".\")\n",
    "            num[1] = zeros + num[1]\n",
    "            new_num = num[0]+\".\"+num[1]\n",
    "            temp[3] = new_num   \n",
    "        frames.append([temp[1],temp[3]])\n",
    "    return frames\n",
    "\n",
    "def add_zeros(frame):\n",
    "    frame=str(frame)\n",
    "    add_zero = 6- len(frame)\n",
    "    for i in range(add_zero):\n",
    "        frame = \"0\"+frame\n",
    "    return frame\n",
    "    \n",
    "    \n",
    "def correct_file(file,frames):\n",
    "    for frame in frames:\n",
    "        file.write(\"Frame: \"+frame[0]+\" Time: \"+frame[1]+\"\\n\")\n",
    "    return\n",
    "    \n",
    "camera_txt = open(FOLDER + \"zed_right.txt\",\"r\")\n",
    "lines = camera_txt.readlines()\n",
    "camera_frames=create_frames(lines)\n",
    "camera_txt.close()\n",
    "\n",
    "camera_txt = open(FOLDER + \"zed_right.txt\",\"w\")\n",
    "correct_file(camera_txt,camera_frames)\n",
    "camera_txt.close()\n",
    "\n",
    "lidar_txt = open(FOLDER + \"velo_lidar.txt\",\"r\")\n",
    "lines = lidar_txt.readlines()\n",
    "lidar_txt.close()\n",
    "lidar_frames = create_frames(lines)\n",
    "\n",
    "lidar_txt = open(FOLDER + \"velo_lidar.txt\",\"w\")\n",
    "correct_file(lidar_txt,lidar_frames)\n",
    "lidar_txt.close()\n",
    "\n",
    "radar_txt = open(FOLDER + \"Navtech_Cartesian.txt\",\"r\")\n",
    "lines = radar_txt.readlines()\n",
    "radar_txt.close()\n",
    "radar_frames=create_frames(lines)\n",
    "\n",
    "radar_txt = open(FOLDER + \"Navtech_Cartesian.txt\",\"w\")\n",
    "correct_file(radar_txt,radar_frames)\n",
    "radar_txt.close()\n",
    "\n",
    "\n",
    "camera_id=0\n",
    "lidar_camera=[]\n",
    "for lidar_id in range(len(lidar_frames)):\n",
    "    if camera_id>=len(camera_frames):\n",
    "        break\n",
    "    c_time = camera_frames[camera_id][1]\n",
    "    l_time = lidar_frames[lidar_id][1]\n",
    "    \n",
    "    if float(l_time)<float(c_time)-0.1:\n",
    "        continue\n",
    "\n",
    "    while(True):\n",
    "        if float(l_time)>float(c_time)+0.1:\n",
    "            camera_id+=1\n",
    "            c_time = camera_frames[camera_id][1]\n",
    "            continue\n",
    "        break\n",
    "    \n",
    "    if float(l_time)<float(c_time)-0.1:\n",
    "        continue\n",
    "    lidar_camera.append([lidar_frames[lidar_id][0],camera_frames[camera_id][0],c_time])\n",
    "    camera_id+=1\n",
    "\n",
    "print(len(lidar_camera))\n",
    "\n",
    "radar_id=0\n",
    "lidar_camera_radar=[]\n",
    "for lidar_cam_id in range(len(lidar_camera)):\n",
    "    if radar_id>=len(radar_frames):\n",
    "        break\n",
    "    cl_time = lidar_camera[lidar_cam_id][2]\n",
    "    r_time = radar_frames[radar_id][1]\n",
    "    if float(cl_time)<float(r_time)-0.1:\n",
    "        continue\n",
    "\n",
    "    while(True):\n",
    "        if float(cl_time)>float(r_time)+0.1:\n",
    "            radar_id+=1\n",
    "            r_time = radar_frames[radar_id][1]\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    if float(cl_time)<float(r_time)-0.1:\n",
    "        continue\n",
    "    lidar_camera_radar.append([lidar_camera[lidar_cam_id][0],lidar_camera[lidar_cam_id][1],r_time])\n",
    "    radar_id+=1\n",
    "\n",
    "print(len(lidar_camera_radar))\n",
    "file = open(FOLDER+\"lidar_to_camera_frame.txt\",\"w\")\n",
    "for frames in lidar_camera_radar:\n",
    "    lidar_frame = add_zeros(frames[0])\n",
    "    camera_frame = add_zeros(frames[1])\n",
    "    timestamp = str(frames[2])\n",
    "    file.write(\"Lidar_Frame: \"+lidar_frame+\" Camera_Frame: \"+camera_frame+\" Timestamp: \"+timestamp+\"\\n\")\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export coco annoation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco_annotation file exported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import radiate_sdk.radiate as rd\n",
    "import numpy as np\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "\n",
    "def assign_class_num(class_name):\n",
    "    if class_name == \"car\":\n",
    "        return 0\n",
    "    elif class_name == \"van\":\n",
    "        return 1\n",
    "    elif class_name == \"truck\":\n",
    "        return 2\n",
    "    elif class_name == \"bus\":\n",
    "        return 3\n",
    "    elif class_name == \"motorbike\":\n",
    "        return 4\n",
    "    elif class_name == \"pedestrian\":\n",
    "        return 5\n",
    "    elif class_name == \"group_of_pedestrians\":\n",
    "        return 6\n",
    "    elif class_name == \"bicycle\":\n",
    "        return 7\n",
    "    else:\n",
    "        print(class_name)\n",
    "\n",
    "\n",
    "seq = rd.Sequence(FOLDER)\n",
    "\n",
    "frames_txt = open(FOLDER+\"lidar_to_camera_frame.txt\",\"r\")\n",
    "frames = frames_txt.readlines()\n",
    "\n",
    "try:\n",
    "    os.mkdir(FOLDER+'coco_annotations')\n",
    "except:\n",
    "    print(\"coco_annotations file already exists\")\n",
    "\n",
    "only_ann_file = open(FOLDER+\"coco_annotations/only_with_annotations.txt\",\"w\")\n",
    "\n",
    "for line in tqdm(frames):\n",
    "    temp = line.split()\n",
    "    lidar,camera,timestamp=temp[1],temp[3],temp[5]\n",
    "\n",
    "    file = open(FOLDER+\"coco_annotations/\"+lidar+\"+\"+camera+\".txt\",\"w\")\n",
    "    \n",
    "    info = seq.get_from_timestamp(float(timestamp))\n",
    "\n",
    "    \n",
    "    if info == {}:\n",
    "        continue\n",
    "    \n",
    "    bboxes = info['annotations']['camera_right_rect']\n",
    "\n",
    "        \n",
    "    for i in range(len(bboxes)):\n",
    "        bbox = [bboxes[i]]\n",
    "        \n",
    "        bbox_array = bbox[0]['bbox_3d']\n",
    "        if bbox_array.size==0:\n",
    "            continue\n",
    "        xmin = np.min(bbox_array[:,0])\n",
    "        ymin = np.min(bbox_array[:,1])\n",
    "        xmax = np.max(bbox_array[:,0])\n",
    "        ymax = np.max(bbox_array[:,1])\n",
    "        \n",
    "        class_num = assign_class_num(bbox[0]['class_name'])\n",
    "\n",
    "        width = abs(xmax-xmin)\n",
    "        height = abs(ymax-ymin)\n",
    "        \n",
    "        coco_bbox=[class_num, xmin,ymin,width,height]\n",
    "\n",
    "        coco_bbox_str = str(coco_bbox[0])+\" \"+str(coco_bbox[1])+\" \"+str(coco_bbox[2])+\" \"+str(coco_bbox[3])+\" \"+str(coco_bbox[4])+\"\\n\"\n",
    "        file.write(coco_bbox_str)\n",
    "\n",
    "\n",
    "    file.close()\n",
    "    if len(bboxes)>0:\n",
    "        only_ann_file.write(lidar+\"+\"+camera+\".png\\n\")\n",
    "only_ann_file.close()\n",
    "\n",
    "print(\"coco_annotation file exported\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create img folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir(FOLDER+'fused_images')\n",
    "    os.mkdir(FOLDER+'fused_images/RGB')\n",
    "    os.mkdir(FOLDER+'fused_images/RGB/img')\n",
    "    os.mkdir(FOLDER+'fused_images/RGB_distance')\n",
    "    os.mkdir(FOLDER+'fused_images/RGB_distance/img')\n",
    "    \n",
    "except:\n",
    "    print(\"fused_images file already exists\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fused images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import radiate_sdk.radiate as rd\n",
    "import numpy as np\n",
    "\n",
    "def export_image(seq,lidar,camera,mode):\n",
    "\n",
    "        data = np.genfromtxt(FOLDER+\"velo_lidar/\"+lidar+\".csv\",delimiter=\",\")\n",
    "\n",
    "        image = cv2.imread(FOLDER+\"zed_right/\"+camera+\".png\")\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        if (mode==\"none\"):\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB/img/\"+lidar+\"+\"+camera+\".png\",image)\n",
    "        \n",
    "\n",
    "        elif (mode == \"projection_same\"):\n",
    "            lidar_proj = seq.project_lidar(data,seq.calib.LidarToRight,seq.calib.right_cam_mat,\"same\")\n",
    "            fusion = seq.overlay_camera_lidar(image_array,lidar_proj)\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB_projection_same/img/\"+lidar+\"+\"+camera+\".png\",fusion)\n",
    "\n",
    "        elif (mode == \"projection_pseudo\"):\n",
    "            lidar_proj = seq.project_lidar(data,seq.calib.LidarToRight,seq.calib.right_cam_mat,\"pseudo_distance\")\n",
    "            fusion = seq.overlay_camera_lidar(image_array,lidar_proj)\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB_projection_pseudo/img/\"+lidar+\"+\"+camera+\".png\",fusion)\n",
    "            \n",
    "\n",
    "        elif (mode == \"pseudo\"):\n",
    "            lidar_proj = seq.project_lidar(data,seq.calib.LidarToRight,seq.calib.right_cam_mat,\"pseudo_distance\")\n",
    "            dist = np.mean(lidar_proj,axis=2)\n",
    "            dist = np.expand_dims(dist,axis=2)\n",
    "            fusion = np.dstack((image_array,dist))\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB_pseudo/img/\"+lidar+\"+\"+camera+\".png\",fusion)\n",
    "            \n",
    "        elif (mode == \"same\"):\n",
    "            lidar_proj = seq.project_lidar(data,seq.calib.LidarToRight,seq.calib.right_cam_mat,\"same\")\n",
    "            dist = np.mean(lidar_proj,axis=2)\n",
    "            dist = np.expand_dims(dist,axis=2)\n",
    "            fusion = np.dstack((image_array,dist))\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB_same/img/\"+lidar+\"+\"+camera+\".png\",fusion)\n",
    "\n",
    "        elif (mode == \"distance\"):\n",
    "            lidar_proj = seq.project_lidar(data,seq.calib.LidarToRight,seq.calib.right_cam_mat,\"distance\")\n",
    "            dist = np.expand_dims(lidar_proj,axis=2)\n",
    "            fusion = np.dstack((image_array,dist))\n",
    "            cv2.imwrite(FOLDER+\"fused_images/RGB_distance/img/\"+lidar+\"+\"+camera+\".png\",fusion)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:01<00:00,  9.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "seq = rd.Sequence(FOLDER)\n",
    "\n",
    "frames_txt = open(FOLDER+\"lidar_to_camera_frame.txt\",\"r\")\n",
    "frames = frames_txt.readlines()\n",
    "\n",
    "for line in tqdm(frames):\n",
    "    temp = line.split()\n",
    "    lidar,camera,timestamp=temp[1],temp[3],temp[5]\n",
    "\n",
    "    export_image(seq,lidar,camera,\"none\")\n",
    "    #export_image(seq,lidar,camera,\"projection_same\")\n",
    "    #export_image(seq,lidar,camera,\"same\")\n",
    "    export_image(seq,lidar,camera,\"distance\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are already deleted\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(FOLDER+'GPS_IMU_Twist')\n",
    "    os.remove(FOLDER+'GPS_IMU_Twist.txt')\n",
    "except:\n",
    "    print(\"GPS has already been removed\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    shutil.rmtree(FOLDER+'Navtech_Cartesian')\n",
    "    shutil.rmtree(FOLDER+'Navtech_Polar')\n",
    "    shutil.rmtree(FOLDER+'zed_left')\n",
    "    shutil.rmtree(FOLDER+'zed_right')\n",
    "    shutil.rmtree(FOLDER+'annotations')\n",
    "    shutil.rmtree(FOLDER+'velo_lidar') \n",
    "\n",
    "    \n",
    "    os.remove(FOLDER+'Navtech_Cartesian.txt')\n",
    "    os.remove(FOLDER+'Navtech_Polar.txt')\n",
    "    os.remove(FOLDER+'zed_left.txt')\n",
    "    os.remove(FOLDER+'velo_lidar.txt')\n",
    "    os.remove(FOLDER+'zed_right.txt')\n",
    "    os.remove(FOLDER+'meta.json')\n",
    "    os.remove(FOLDER+'lidar_to_camera_frame.txt')\n",
    "\n",
    "\n",
    "except:\n",
    "    print(\"Files are already deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOLDERS = ['city_1_0','city_1_1','city_1_3','city_2_0',\n",
    "#           'junction_1_0','junction_1_1','junction_1_2',\n",
    "#           'motorway_1_0','motorway_2_0','motorway_2_1',\n",
    "#           'rural_1_1','rural_1_3','fog_6_0','fog_8_0',\n",
    "#           'fog_8_1','fog_8_2','night_1_0','night_1_1',\n",
    "#           'night_1_2','night_1_3','rain_2_0','rain_3_0',\n",
    "#           'rain_4_0','rain_4_1','snow_1_0']\n",
    "FOLDERS = [FOLDER[22:]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create coco_annotation json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for FOLDER in tqdm(FOLDERS):\n",
    "    FOLDER = 'Radiate_Image_Dataset/'+ FOLDER+\"/\"\n",
    "    img_folder = FOLDER + \"fused_images/RGB/img/\"\n",
    "    annotation_folder = FOLDER + \"coco_annotations\"\n",
    "    img_list = os.listdir(img_folder)\n",
    "    annotation_list = os.listdir(annotation_folder)\n",
    "\n",
    "    #Create the basic info of the annotation file\n",
    "    dic = {\n",
    "    \"info\":\n",
    "        {\"year\":\"2023\",\n",
    "        \"version\":\"1\",\n",
    "        \"description\":\"Radiate Dataset\",\n",
    "        \"contributor\":\"Heriot-Watt University\",\n",
    "        \"url\":\"https://pro.hw.ac.uk/radiate/\",\n",
    "        \"date_created\":\"2020-03-15\"},\n",
    "    \"licenses\":\n",
    "        [{\"id\":1,\n",
    "        \"url\":\"https://choosealicense.com/licenses/mit/\",\n",
    "        \"name\":\"MIT\"}],\n",
    "    \"categories\":[\n",
    "        {\"id\":0,\n",
    "        \"name\":\"car\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":1,\n",
    "        \"name\":\"van\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":2,\n",
    "        \"name\":\"truck\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":3,\n",
    "        \"name\":\"bus\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":4,\n",
    "        \"name\":\"motorbike\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":5,\n",
    "        \"name\":\"pedestrian\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":6,\n",
    "        \"name\":\"group_of_pedestrians\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":7,\n",
    "        \"name\":\"bicycle\",\n",
    "        \"supercategory\":\"none\"}],\n",
    "    \"images\":[],\n",
    "    \"annotations\":[]}\n",
    "\n",
    "\n",
    "    #Add all the images\n",
    "    for img in img_list:\n",
    "        if img == '_annotations.coco.json':\n",
    "            continue\n",
    "        im = cv2.imread(img_folder+img)\n",
    "        temp_dic = {\n",
    "            \"id\":len(dic['images']),\n",
    "            \"license\":1,\n",
    "            \"file_name\":img,\n",
    "            \"height\":im.shape[0],\n",
    "            \"width\":im.shape[1],\n",
    "            \"date_captured\":\"2020-03-15\"}  \n",
    "        dic['images'].append(temp_dic)\n",
    "\n",
    "    #Add the bounding boxes\n",
    "    for i in range(len(annotation_list)-1):\n",
    "        file_path = os.path.join(annotation_folder, annotation_list[i])\n",
    "        if (annotation_list[i]== \"only_with_annotations.txt\"):\n",
    "            continue\n",
    "        with open(file_path,'r') as file:\n",
    "            #search for image id\n",
    "            for idx in range(len(dic['images'])):\n",
    "                if annotation_list[i][:-4] == dic['images'][idx][\"file_name\"][:-4]:\n",
    "                    index = idx\n",
    "\n",
    "            bbox_list= file.read().split(\"\\n\")\n",
    "            for j in range(len(bbox_list)-1):\n",
    "                box = bbox_list[j]\n",
    "                box = box.split(\" \")\n",
    "                box[1],box[2],box[3],box[4]=int(box[1]),int(box[2]),int(box[3]),int(box[4])\n",
    "                #in case a bounding box is out of the boundaries of the image\n",
    "                img_height = dic['images'][0]['height']\n",
    "                img_width = dic['images'][0]['width']\n",
    "                if box[1]<0:\n",
    "                    w = abs(box[1]+box[3])\n",
    "                    box[1] = 0\n",
    "                    box[3] = w \n",
    "                if box[2]<0:\n",
    "                    h = abs(box[2] +box[4])\n",
    "                    box[2]=0\n",
    "                    box[4] = h\n",
    "                \n",
    "                if box[1]>img_width:\n",
    "                    box[1]=img_width\n",
    "                if box[2]>img_height:\n",
    "                    box[2]=img_height\n",
    "\n",
    "                if box[1]+box[3]>img_width:\n",
    "                    box[3]=img_width-box[1]\n",
    "                if box[2]+box[4]>img_height:\n",
    "                    box[4]=img_height-box[2]\n",
    "\n",
    "                if box[0]=='None':\n",
    "                    box[0]='7'\n",
    "                \n",
    "                temp_dic={\n",
    "                    \"id\":len(dic['annotations']),\n",
    "                    \"image_id\":dic['images'][index]['id'],\n",
    "                    \"category_id\":box[0],\n",
    "                    \"bbox\":[int(box[1]),int(box[2]),int(box[3]),int(box[4])],\n",
    "                    \"area\":int(box[3])*int(box[4]),\n",
    "                    \"segmentation\":[],\n",
    "                    \"iscrowd\":0}\n",
    "                if temp_dic['image_id']<0:\n",
    "                    temp_dic['image_id']=0\n",
    "                dic['annotations'].append(temp_dic)\n",
    "\n",
    "\n",
    "    json_object = json.dumps(dic, indent=5)\n",
    "    \n",
    "    with open(FOLDER+\"fused_images/RGB/_annotations.coco.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "    with open(FOLDER+\"fused_images/RGB_distance/_annotations.coco.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "for FOLDER in FOLDERS:\n",
    "    FOLDER = 'Radiate_Image_Dataset/'+ FOLDER+\"/\"\n",
    "    try:\n",
    "        os.mkdir(FOLDER+'Annotated')\n",
    "    except:\n",
    "        print(FOLDER+'Annotated  already exists')\n",
    "\n",
    "\n",
    "for FOLDER in tqdm(FOLDERS):\n",
    "    FOLDER = 'Radiate_Image_Dataset/'+ FOLDER+\"/\"\n",
    "    img_folder = FOLDER + \"fused_images/RGB/img/\"\n",
    "    annotation_folder = FOLDER + \"coco_annotations\"\n",
    "    img_list = os.listdir(img_folder)\n",
    "    annotation_list = os.listdir(annotation_folder)\n",
    "\n",
    "    json_path = FOLDER+\"fused_images/RGB/_annotations.coco.json\"\n",
    "    with open(json_path, \"r\") as file:\n",
    "        data_dic = json.load(file)\n",
    "        \n",
    "\n",
    "    #random_idx = random.randint(0, len(data_dic['images'])-1)\n",
    "\n",
    "    for random_idx in range(len(data_dic['images'])):\n",
    "\n",
    "        random_img = data_dic['images'][random_idx]\n",
    "\n",
    "        img_path = img_folder +random_img['file_name']\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "        image_array = np.asarray(image)\n",
    "        image_array = image_array[:,:,:3]\n",
    "\n",
    "\n",
    "        transform = transforms.ToPILImage()\n",
    "        final_image = transform(image_array)\n",
    "\n",
    "        draw = ImageDraw.Draw(final_image)\n",
    "\n",
    "        random_img_id = random_img['id']\n",
    "\n",
    "        for ann in data_dic['annotations']:\n",
    "            if ann['image_id']==random_img_id:\n",
    "                xmin,ymin,width,height = ann['bbox'][0], ann['bbox'][1], ann['bbox'][2],ann['bbox'][3]\n",
    "                draw.rectangle([xmin, ymin, xmin + width, ymin + height], outline='green', width=2)\n",
    "\n",
    "        final_image.save(f\"{FOLDER}Annotated/Image #{random_idx}.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train-test-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:14, Train:10, Test:1, Validation:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import os \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "EXPERIMENTS = ['RGB/','RGB_distance/']\n",
    "\n",
    "\n",
    "for FOLDER in tqdm(FOLDERS):\n",
    "    FOLDER = 'Radiate_Image_Dataset/'+ FOLDER+\"/\"\n",
    "    json_path = FOLDER+\"fused_images/RGB/_annotations.coco.json\"\n",
    "    with open(json_path, \"r\") as file:\n",
    "        data_dic = json.load(file)\n",
    "\n",
    "    random.seed(42)\n",
    "    random.shuffle(data_dic['images'])\n",
    "\n",
    "    #Shuffle and Separate train, test, val\n",
    "    train_percent = 0.70 \n",
    "    valid_percent = 0.20 \n",
    "    test_percent = 0.10\n",
    "\n",
    "    total = len(data_dic['images'])\n",
    "    train = round(train_percent*total)\n",
    "    test = round(test_percent*total)\n",
    "    valid = round(valid_percent*total)\n",
    "\n",
    "\n",
    "    train_set = data_dic['images'][:train]\n",
    "    test_set = data_dic['images'][train:train+test]\n",
    "    valid_set = data_dic['images'][train+test:]\n",
    "\n",
    "    train_dic = {\n",
    "    \"info\":\n",
    "        {\"year\":\"2023\",\n",
    "        \"version\":\"1\",\n",
    "        \"description\":\"Radiate Dataset\",\n",
    "        \"contributor\":\"Heriot-Watt University\",\n",
    "        \"url\":\"https://pro.hw.ac.uk/radiate/\",\n",
    "        \"date_created\":\"2020-03-15\"},\n",
    "    \"licenses\":\n",
    "        [{\"id\":1,\n",
    "        \"url\":\"https://choosealicense.com/licenses/mit/\",\n",
    "        \"name\":\"MIT\"}],\n",
    "    \"categories\":[\n",
    "        {\"id\":0,\n",
    "        \"name\":\"car\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":1,\n",
    "        \"name\":\"van\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":2,\n",
    "        \"name\":\"truck\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":3,\n",
    "        \"name\":\"bus\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":4,\n",
    "        \"name\":\"motorbike\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":5,\n",
    "        \"name\":\"pedestrian\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":6,\n",
    "        \"name\":\"group_of_pedestrians\",\n",
    "        \"supercategory\":\"none\"},\n",
    "        {\"id\":7,\n",
    "        \"name\":\"bicycle\",\n",
    "        \"supercategory\":\"none\"}],\n",
    "    \"images\":[],\n",
    "    \"annotations\":[]}\n",
    "\n",
    "    test_dic = train_dic.copy()\n",
    "    valid_dic = train_dic.copy()\n",
    "\n",
    "    train_dic['images']=train_set\n",
    "    test_dic['images']=test_set\n",
    "    valid_dic['images']=valid_set\n",
    "\n",
    "    temp_ann = []\n",
    "    for img in train_set:\n",
    "        for ann in data_dic['annotations']:\n",
    "                if ann['image_id'] == img['id']:\n",
    "                     temp_ann.append(ann)\n",
    "    train_dic['annotations'] = temp_ann\n",
    "    \n",
    "    temp_ann = []\n",
    "    for img in test_set:\n",
    "        for ann in data_dic['annotations']:\n",
    "                if ann['image_id'] == img['id']:\n",
    "                    temp_ann.append(ann)\n",
    "    test_dic['annotations'] = temp_ann\n",
    "\n",
    "    temp_ann = []\n",
    "    for img in valid_set:\n",
    "        for ann in data_dic['annotations']:\n",
    "                if ann['image_id'] == img['id']:\n",
    "                    temp_ann.append(ann)\n",
    "    valid_dic['annotations'] = temp_ann\n",
    "\n",
    "    #Save annotations in folders  \n",
    "    train_json = json.dumps(train_dic, indent=5)\n",
    "    test_json = json.dumps(test_dic, indent=5)\n",
    "    valid_json = json.dumps(valid_dic, indent=5) \n",
    "\n",
    "    for EXPERIMENT in EXPERIMENTS:\n",
    "        try:\n",
    "            os.mkdir(FOLDER+\"fused_images/\"+EXPERIMENT+\"train\")\n",
    "            os.mkdir(FOLDER+\"fused_images/\"+EXPERIMENT+\"test\")\n",
    "            os.mkdir(FOLDER+\"fused_images/\"+EXPERIMENT+\"valid\")\n",
    "        except:\n",
    "            files = glob.glob(FOLDER+\"fused_images/\"+EXPERIMENT+\"train/*\")\n",
    "            for f in files:\n",
    "                 os.remove(f)\n",
    "            files = glob.glob(FOLDER+\"fused_images/\"+EXPERIMENT+\"test/*\")\n",
    "            for f in files:\n",
    "                 os.remove(f)\n",
    "            files = glob.glob(FOLDER+\"fused_images/\"+EXPERIMENT+\"valid/*\")\n",
    "            for f in files:\n",
    "                 os.remove(f)\n",
    "\n",
    "        #Copy images to folders and get annotations\n",
    "        for img in train_set:\n",
    "            img_path = FOLDER+\"fused_images/\"+EXPERIMENT+\"img/\"+img['file_name']\n",
    "            with Image.open(img_path) as image:\n",
    "                    image.save(FOLDER+\"fused_images/\"+EXPERIMENT+'train/'+img['file_name'])\n",
    "\n",
    "        for img in test_set:\n",
    "            img_path = FOLDER+\"fused_images/\"+EXPERIMENT+\"img/\"+img['file_name']\n",
    "            with Image.open(img_path) as image:\n",
    "                    image.save(FOLDER+\"fused_images/\"+EXPERIMENT+'test/'+img['file_name'])\n",
    "\n",
    "        for img in valid_set:\n",
    "            img_path = FOLDER+\"fused_images/\"+EXPERIMENT+\"img/\"+img['file_name']\n",
    "            with Image.open(img_path) as image:\n",
    "                    image.save(FOLDER+\"fused_images/\"+EXPERIMENT+'valid/'+img['file_name'])\n",
    "\n",
    "\n",
    "        with open(FOLDER+\"fused_images/\"+EXPERIMENT+\"train/_annotations.coco.json\", \"w\") as file:\n",
    "            file.write(train_json)\n",
    "\n",
    "        with open(FOLDER+\"fused_images/\"+EXPERIMENT+\"test/_annotations.coco.json\", \"w\") as file:\n",
    "            file.write(test_json)\n",
    "\n",
    "        with open(FOLDER+\"fused_images/\"+EXPERIMENT+\"valid/_annotations.coco.json\", \"w\") as file:\n",
    "            file.write(valid_json)\n",
    "    print(f'Total:{total}, Train:{train}, Test:{test}, Validation:{valid}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
